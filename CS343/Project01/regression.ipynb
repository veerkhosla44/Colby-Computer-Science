{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veer Khosla and Saad Khan\n",
    "\n",
    "Fall 2024\n",
    "\n",
    "CS 343: Neural Networks\n",
    "\n",
    "Project 1: Single-layer networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from adaline import Adaline\n",
    "\n",
    "# Set the color style so that Professor Layton can see your plots\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "# Make the font size larger\n",
    "plt.show()\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Turn off scientific notation when printing\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "def plot_adaline_train(net, loss_list, acc_list, plotMarkers=False, title='ADALINE'):\n",
    "    '''Helper plotting function provided for you.'''\n",
    "    n_epochs = len(loss_list)\n",
    "\n",
    "    x = np.arange(1, n_epochs+1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "    fig.suptitle(f'{title} ({n_epochs} epochs)')\n",
    "\n",
    "    curveStr = '-r'\n",
    "    if plotMarkers:\n",
    "        curveStr += 'o'\n",
    "\n",
    "    ax1.plot(x, loss_list, curveStr)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss (Sum squared error)')\n",
    "    ax2.plot(x, acc_list, curveStr)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paste in your code to load Old Faithful data with standardized features below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcc8e1562b8d8f21d933e2280c22c9e1",
     "grade": false,
     "grade_id": "cell-2b7d463960f66986",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Neural network for regression\n",
    "\n",
    "Given ADALINE's linear (identity) activation and sum-of-squares loss function, the learned weights can be used for more than just classification. In this task, you will use ADALINE to perform a linear regression (*the same neural network offers another interpretation of what you did in CS251!*).\n",
    "\n",
    "### Goal\n",
    "\n",
    "Your goal is to get an ADALINE network to predict `waiting` from `eruptions`. That is, you are setting up a simple (bivariate) linear regression with equation $$y_i = m \\times x_i + b$$where the \"x\" variable (*predictor variable*) is `eruptions` and the \"y\" variable (*response variable*) is `waiting` (raw).\n",
    "\n",
    "**Ultimately, you want to draw a regression line *through* the Old Faithful data clusters to *join* rather than divide them.**\n",
    "\n",
    "### Design\n",
    "\n",
    "You can do the regression with the exact network you have currently implemented. **You shouldn't make any code changes to your `Adaline` class.**  In the cell below, use your network to set up the regression by making appropriate design choices:\n",
    "- Network input features: How many? What should they be?\n",
    "- Weights: What do they mean in this problem context?\n",
    "- What are the \"classes\"?\n",
    "\n",
    "### Tips\n",
    "\n",
    "- I suggest using the standardized version of the predictor (otherwise you may run into numeric stability issues), but it's fine to use the raw/unstandardized response variable. \n",
    "- Default hyperparameters should work well.\n",
    "- You may need to add a singleton dimension after selecting your input predictor feature below so that your existing code works i.e. `shape=(272,1)`, NOT `shape=(272,)`\n",
    "\n",
    "**Write your training code in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40f618689c7fa05921e917c3a69b32b6",
     "grade": false,
     "grade_id": "cell-9d2e270808353b69",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, **create a scatter plot of the data and the overlayed regression line**. Have the x-axis map onto standardized `eruptions` and y-axis onto raw `waiting` values.\n",
    "\n",
    "### Tips\n",
    "- You will need to leverage the model linear equation to go from x values to predicted y values. $y_i = m \\times x_i + b$\n",
    "- Look at the class boundary plot code that you used for classification. You will need to generate linearly spaced x values before plotting your regression y values on your regression line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "469a09f5d00d5bea9e3774f035ef6e7a",
     "grade": false,
     "grade_id": "cell-879900a33d759477",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: ADALINE and logistic regression\n",
    "\n",
    "In this task, you will extend ADALINE to logistic regression, where we explicitly represent the probability of class membership.\n",
    "\n",
    "For example data point $i$ is 80% likely to be in class A and 20% in class B.\n",
    "\n",
    "**Remember:** Despite the name, logistic regression is actually about solving a **classification** problem. So this is more similar to Task 3 than Task 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Implement logistic regression\n",
    "\n",
    "Create a subclass of `Adaline` called `AdalineLogistic` in a new file called `adaline_logistic.py`. **Only override existing methods as needed to make the following changes. DO NOT MODIFY `adaline.py` FOR ANY REASON!!**.\n",
    "\n",
    "#### Design\n",
    "\n",
    "1. Use the sigmoid activation function. $z = f(x) = \\frac{1}{1+e^{-x}}$\n",
    "2. Represent the output classes as 0 or +1. This should require a code change (activation values >=0.5 are classified as 1, otherwise class 0) and preprocessing of the old faithful data.\n",
    "3. Use the cross-entropy loss function: $\\sum_{i=1}^n \\left [ -y_i Log(z_i) - (1-y_i)Log(1 - z_i) \\right ] $\n",
    "where $z_i$ is the activation to input sample $i$ and $y_i$ is the corresponding $i^{th}$ class label (0 or 1).\n",
    "\n",
    "\n",
    "#### Todo below:\n",
    "\n",
    "1. Train your network using the standardized Old Faithful data. Default hyperparameters should work fine.\n",
    "2. Plot your loss and accuracy as a function of epoch.\n",
    "3. Plot the logistic regression decision boundary and the data (Use your code from Task 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "**Question 11.** Why do we need to relabel the classes from -1/+1 to 0/1 when training a logistic regression network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 11:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b55a295ec33c6243c01cf2f7c10e99e",
     "grade": true,
     "grade_id": "cell-9a2becfa7b47913e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaline_logistic import AdalineLogistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcfcc172047f6c2f42723034d04fa901",
     "grade": false,
     "grade_id": "cell-a4dc341d81471e83",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ca510cd74fd6ff90b5ed9442bbe3038",
     "grade": false,
     "grade_id": "cell-559151d22cf1b5ee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Test point probabilities\n",
    "\n",
    "#### Questions\n",
    "\n",
    "**Question 12.** (a) Determine the probability that the following test points belong to **both classes**:\n",
    "\n",
    "Format: standardized (eruptions, waiting)\n",
    "- (0.4, 0.98)\n",
    "- (0.5, -2)\n",
    "- (-1, 0.5)\n",
    "\n",
    "(b) Interpret what your probabilities make sense in light of decision boundary plot you made in Task 5a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 12:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63ce9ebec0c9116f9a34402289d461b1",
     "grade": true,
     "grade_id": "cell-9a21170064daf78b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69b9a96f6d820023c610f16dc15f84a2",
     "grade": false,
     "grade_id": "cell-c0efaecda78f3e8d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "Before starting your extensions, please keep these guidelines in mind.\n",
    "\n",
    "### General guidelines\n",
    "\n",
    "1. Never integrate extensions into your base project so that they change the expected behavior of core functions. If your extension changes the core design/behavior, no problem, duplicate your working base project and add features from there.\n",
    "2. Check the rubric to keep in mind how extensions on this project will be graded.\n",
    "3. While I may consult your code and \"written log\" of what you did, **I am grading your extensions based on what you present in your 3-5 min video.**\n",
    "3. I suggest documenting your explorations in a \"log\" or \"lab notebook\" style (i.e. documenting your thought/progression/discovery/learning process). I'm not grading your writing, so you can keep it succinct. **Whatever is most useful to you to remember what you did.** \n",
    "4. I suggest taking a hypothesis driven approach. For example \"I was curious about X so I explored Y. I found Z, which was not what I expected because..., so then tried A...\"\n",
    "5. Make plots to help showcase your results.\n",
    "6. **More is not necessarily better.** Generally, a small number of \"in-depth\" extensions count for more than many \"shallow\" extensions.\n",
    "\n",
    "### AI guidelines\n",
    "\n",
    "You may use AI in mostly any capacity for extensions. However, keep in mind:\n",
    "1. There is no need to use AI at all!\n",
    "2. You are welcome to use AI as a tool (e.g. automate something that is tedious, help you get unstuck, etc.). However, you should be coding, you should be thinking, you should be writing, you should be creating. If you are spending most (or even close to most) of your time typing into a chatbot and copy-pasting, you have probably gone too far with AI use.\n",
    "3. I don't find large volumes of AI generated code/text/plots to be particularly impressive and you risk losing my interest while grading. Remember: I'm grading your extensions based on your video presentation. **More is not necessarily better.**\n",
    "\n",
    "### Video guidelines\n",
    "\n",
    "1. Please try to keep your video to 5 minutes (*I have other projects to grade!*). If you turn in a longer video, I make no promise that I will watch more than 5 minutes.\n",
    "2. Your screen should be shared as you show me what you did. A live video of your face should also appear somewhere on the screen (e.g. picture-in-picture overlay / split screen).\n",
    "3. Your partner should join you for the video and take turns talking, but, if necessary, it is fine to have one team member present during the record the video.\n",
    "4. Do not simply read text from your notebook, do not read from a prepared script. I am not grading how polished your video presentation is (see extension grading criteria on rubric). \n",
    "5. I am looking for original and creative explorations sparked by your curiosity/interest/passion in a topic. This should be apparent in your video.\n",
    "6. Be natural, don't feel the need to impress me with fancy language. If it is helpful, imagine that we are talking one-on-one about your extension. Tell me what you did :)\n",
    "\n",
    "### Extension ideas\n",
    "\n",
    "1. Extend the ADALINE model to multi-class classification using the One-Vs-Rest (OvR) method. Recall that with this scheme, we train multiple networks with each of the $n$ output classes serving as the +1 class (others set to 0 class). For example, for classes [a, b, c] would would train the networks with the following class labels: [1, 0, 0], [0, 1, 0], [0, 0, 1], respectively. We then classify based on the class that generates the highest max probability / activation value. Test it on a dataset with more than two classes (e.g. Iris). \n",
    "2. Create plots of the ADALINE regression after training on different numbers of epochs. One options is to plot all the curves in a single plot and establish a color scheme for time so that the viewer can visually discern the time sequence. Another possibility is to create a NxM grid of plots showing the progression (be sure to label the titles with #epochs).\n",
    "3. Demonstrate how ADALINE can handle multiple linear regression.\n",
    "4. Test the performance of single layer neural networks at classifying a binary class dataset of your choice.\n",
    "5. Compare the performance of ADALINE, Perceptron, and Logistic Regression single-layer networks in additional ways and/or with additional datasets.\n",
    "6. Research, implement, and analyze a neural network technique called early stopping. In essence, you stop training when the change in loss between successive epochs drops below some threshold. You can make your early stopping implementation fancier. For example, only stop if the change relative to the average loss over the most recent few epochs is less than the tolerance. Why could this be an improvement over the other method?\n",
    "7. K-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
